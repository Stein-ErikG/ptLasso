---
title: "Introduction"
output: 
  bookdown::pdf_document2:
   toc: false
bibliography: ptLasso.bib
vignette: >
  %\VignetteIndexEntry{Introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  % \VignetteDepends{rpart}
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introduction to pretraining

Suppose we have a dataset spanning ten cancers and we want to fit a lasso penalized Cox model to predict survival time. Some of the cancer classes in our dataset are large  (e.g. breast, lung) and some are small (e.g. head and neck). There are two obvious approaches: (1) fit a "pancancer model" to the entire training set and use it to make predictions for all cancer classes and (2) fit a separate (class specific) model for each cancer and use it to make predictions for that class only. Pretraining is a method that bridges these two options; it has a hyperparameter that allows you to fit the pancancer model, the class specific models, and everything in between. 

`ptLasso` is a package that fits pretrained models using the `glmnet` package (@glmnet), including lasso, elasticnet and ridge models .

Our example dataset consisting of ten different cancers is called __input grouped__. There is a grouping on the rows of $X$ and each row belongs to one of the cancer classes. Alternatively, data can be __target grouped__, where there is no grouping on the rows of $X$, but we have (for example) a multinomial outcome. We could fit one multinomial model, or we could fit a set of one-vs-rest models. Pretraining again bridges the two approaches, and this is described in detail in the section "Target grouped data". The remainder of this introduction describes the input grouped setting. 

Pretraining is a general method to pass information from one model to another -- it has many uses beyond what has already been discussed here, including time series data, multi-response data with mixed response types, and multitask learning. Some of these modeling tasks are not supported by the `ptLasso` package, and this vignette shows how to do pretraining for them using the `glmnet` package.

Before we describe pretraining in more detail, we will first give a quick review of the lasso.

## Review of the lasso
For the Gaussian family with data $(x_i,y_i), i=1,2,\ldots n$, the lasso has the form 
\begin{equation}
{\rm argmin}_{\beta_0, \beta} \frac{1}{2} \sum_{i=1}^n(y_i- \beta_0 -\sum_{j=1}^p x_{ij}\beta_j)^2 + \lambda \sum_{j=1}^p |\beta_j |.
\end{equation}
Varying the  regularization parameter $\lambda \ge 0$ yields a path of solutions: an optimal value
$\hat\lambda$ is usually chosen by cross-validation, using for example the `cv.glmnet` function from the package `glmnet`.

In GLMs and $\ell_1$-~regularized GLMs, one can include an _offset_: a pre-specified $n$-vector that is included as an additional column to the feature matrix, but whose weight $\beta_j$ is fixed at 1. Secondly, one can generalize the $\ell_1$ norm to a weighted norm, taking the form
 \begin{equation}
 \sum_j {\rm pf}_j |\beta_j |
 \end{equation}
where each ${\rm pf}_j \ge 0$ is a __penalty factor__ for feature $j$. At the extremes, a penalty factor of zero implies no penalty and means that the feature will always be included in the model; a penalty factor of $+\infty$ leads to that feature being discarded (i.e., never entered into the model).

## Details of pretraining
Pretraining model fitting happens in two steps. First, train a model using the full data:
\begin{equation}
 	\hat{\mu}_0, \hat{\theta}_2, \dots, \hat{\theta}_K, \hat{\beta}_0 = \arg \min_{\mu, \theta_1, \dots, \theta_{k-1}, \beta} \frac{1}{2} \sum_{k=1}^K \| y_k - \left(\mu \mathbf{1} + \theta_k \mathbf{1} + X_k \beta\right) \|_2^2 + \lambda ||\beta||_1,
\end{equation}
where:

* $X_k, y_k$ are the observations in group $k$,
* $\theta_k$ is the group specific intercept for group $k$ (by convention, $\hat{\theta}_1 = 0$),
* $\mu, \beta$ are the overall intercept and coefficients, 
* and $\lambda$ is a hyperparameter that has been chosen (perhaps the value minimizing the CV error). 

Define $S(\hat\beta_0)$ to be the support set (the nonzero coefficients) of $\hat{\beta}_0$. 

Then, for each group $k$, fit an _individual_ model: find $\hat{\beta}_k$ and $\hat{\mu}_k$ such that
\begin{eqnarray}
&& \hat{\mu}_k, \hat{\beta}_k = \arg \min_{\mu, \beta} \frac{1}{2}  \| y_k - (1-\alpha) \left(\hat{\mu}_0 \mathbf{1} + \hat{\theta}_k \mathbf{1} + X_k \hat{\beta}_0\right) - (\mu \mathbf{1} + X_k \beta) \|_2^2 +
\cr && \phantom{\hat{\mu}_k, \hat{\beta}_k} \lambda \sum_{j=1}^p \Bigl[ I(j \in S(\hat{\beta}_0))+ \frac{1}{\alpha} I(j \notin S(\hat{\beta}_0))  \Bigr] |\beta_{j}|,
\label{eq:model}
\end{eqnarray}
where $\lambda > 0$ and $\alpha\in [0,1]$ are hyperparameters that may be chosen through cross validation. 

Note that this is a lasso linear regression model with _offset_ $(1-\alpha) \left(\hat{\mu}_0 \mathbf{1} + \hat{\theta}_k \mathbf{1} + X_k \hat{\beta}_0\right)$ and coefficient $j$ has _penalty factor_ 1 if $j \in S(\hat{\beta}_0)$ and $\frac{1}{\alpha}$ otherwise.

Notice that when $\alpha=0$, this returns the overall model fine tuned for each group: this second stage model is only allowed to fit the residual $y_k - \left(\hat{\mu}_0 \mathbf{1} + \hat{\theta}_k \mathbf{1} + X_k \hat{\beta}_0\right)$, and the penalty factor $I(j \in S(\hat{\beta}_0))+ \infty I(j \notin S(\hat{\beta}_0))$ disallows the use of $\beta_j$ unless it was already selected by the overall model. 

At the other extreme, when $\alpha=1$, this is equivalent to fitting a separate model for each class. There is no offset, and the lasso penalty is 1 for all features (the usual lasso penalty).

## `ptLasso` under the hood
All model fitting in `ptLasso` is done with `cv.glmnet`. The first step of pretraining is a straightforward call to `cv.glmnet`; the second step is done by calling `cv.glmnet` with:

1.`offset` $(1-\alpha) \left(\hat{\mu_0} \mathbf{1} + X_k \hat{\beta_0}\right)$ and
2.`penalty.factor`, the $j^\text{th}$ entry of which is $1$ if $j \in S(\hat{\beta_0})$ and $\frac{1}{\alpha}$ otherwise.

Because `ptLasso` uses `cv.glmnet`, it inherits most of the virtues of the `glmnet` package: for example, it handles sparse input-matrix formats, as well as range constraints on coefficients. 

Additionally, one call to `ptLasso` fits an overall model, pretrained class specific models, and class specific models for each group (without pretraining). The `ptLasso` package also includes methods for prediction and plotting, and a function that performs K-fold cross-validation.

# Installation

To install this package, do the following.
```{r, echo=TRUE, eval=FALSE}
require(remotes)
remotes::install_github("erincr/ptLasso")
```


# Quick start

This section shows how to use the main functions in `ptLasso`. We will show more details and options in the following sections. First, we load the `ptLasso` package:
```{r setup}
require(ptLasso)
```

To show how to use `ptLasso`, we'll simulate data with 5 groups and a continuous response using the helper function `gaussian.example.data`. There are $n = 200$ observations in each group and $p = 120$ features. All groups share 10 informative features; though the features are shared, they have different coefficient values. Each group has 10 additional features that are specific to that group, and all other features are uninformative. The coefficients for the 5 groups are in Table \@ref(tab:coefs).

```{r coefs, echo = FALSE}
coef.table = cbind(cbind(
  3*(1:5),
  c(3, rep(0, 4)),
  c(0, 3, rep(0, 3)),
  c(rep(0, 2), 3, rep(0, 2)),
  c(rep(0, 3), 3, 0),
  c(rep(0, 4), 3)
), 0)
rownames(coef.table) = paste0("group ", 1:5)
colnames(coef.table) = c("1-10", "11-20", "21-30", "31-40", "41-59", "51-60", "61-120")

require(knitr)
kable(
  coef.table, booktabs = TRUE,
  caption = 'Coefficients for simulating input grouped data',
  format = "latex"
)
```


```{r}
set.seed(1234)

out = gaussian.example.data()
x = out$x; y = out$y; groups = out$groups

outtest = gaussian.example.data()
xtest = outtest$x; ytest = outtest$y; groupstest = outtest$groups

```

```{r, echo=F, eval=F}
set.seed(1234)

# Train data
# We will have 500 observations split evenly into two groups.
n = 500; p = 100; sigma = 10
x = matrix(rnorm(n*p), n, p)
groups = c(rep(1, n/2), rep(2, n/2))

# We define 10 features that are shared across groups.
# Though the features are shared, they have different coefficient values.
# Each group has 10 additional features of their own.
# The remaining features are unrelated to the outcome.
beta.group1 = c(rep(3, 10), rep(3, 10), rep(0, 10), rep(0, p - 30))
beta.group2 = c(rep(3, 10), rep(0, 10), rep(3, 10), rep(0, p - 30))

# Now we define y = x %*% beta + noise.
y = rep(0, n)
y[groups == 1] = x[groups == 1, ] %*% beta.group1
y[groups == 2] = x[groups == 2, ] %*% beta.group2
y = y + sigma * rnorm(n)

# Test data - same as train.
xtest = matrix(rnorm(n*p), n, p)
groupstest = c(rep(1, n/2), rep(2, n/2))
ytest = rep(0, n)
ytest[groupstest == 1] = xtest[groups == 1, ] %*% beta.group1
ytest[groupstest == 2] = xtest[groups == 2, ] %*% beta.group2
ytest = ytest + sigma * rnorm(n)
```

Now we are ready to fit a model using `ptLasso`. We'll start by defining the pretraining hyperparamter $\alpha = 0.5$ (randomly chosen). In practice we recommend using a validation set to measure performance for a few different choices of $\alpha$, or using `cv.ptLasso`, which will recommend a choice of $\alpha$ based on CV performance.

```{r}
fit <- ptLasso(x, y, groups, alpha = 0.5)
```

The function `ptLasso` used `cv.glmnet` to fit 11 models: 

- the *overall* model (using all 5 groups), 
- the 5 *pretrained* models (one for each group) and
- the 5 *individual* models (one for each group).

A call to `plot` will show us the cross validation curves for each model. The top row shows the overall model, the middle row the pretrained models, and the bottom row the individual models.

```{r, fig.width=7, fig.height=6, dpi=100}
plot(fit)
```

`predict` makes predictions from all $11$ models. It returns a list containing:

1. `yhatoverall` (predictions from the overall model), 
2. `yhatpre` (predictions from the pretrained models) and 
3. `yhatind` (predictions from the individual models).

By default, `predict` uses `lambda.min` for all $11$ `cv.glmnet` models; you could instead specify `s = lambda.1se` or use a numeric value. Whatever value of $\lambda$ you choose will be used for all models (overall, pretrained and individual).

```{r}
preds = predict(fit, xtest, groupstest=groupstest)
```

If you also provide `ytest` (e.g. for model validation), `predict` will additionally compute performance measures. 
<!---For continuous outcomes, `predict` computes the mean squared prediction error by default; the argument `type.measure = "mae"` would compute the mean absolute prediction error instead.--->

```{r}
preds = predict(fit, xtest, groupstest=groupstest, ytest=ytest)
preds
```

To access the coefficients of the fitted models, use `coef` as usual. This returns a list with the coefficients of the individual models, pretrained models and overall models, as returned by `glmnet`.
```{r}
all.coefs = coef(fit, s= "lambda.min")
names(all.coefs)
```

The entries for the individual and pretrained models are lists with one entry for each group. Because we have 5 groups, we'll have 5 sets of coefficients.
```{r}
length(all.coefs$pretrain)
```

The first few coefficients for group 1 from the pretrained model are:
```{r}
head(all.coefs$pretrain[[1]])
```

When we used `ptLasso` to fit a model, we chose $\alpha = 0.5$. If we want to use cross validation to compare many choices of $\alpha$, we can use `cv.ptLasso`. After fitting, the `cv.ptLasso` object will print out the cross validated mean squared error for (1) the overall model, (2) the pretrained models for all compared choices of $\alpha$ and (3) the individual models.

```{r}
cvfit <- cv.ptLasso(x, y, groups)
cvfit
```

We can plot the `cv.ptLasso` object to visualize performance as a function of $\alpha$:
```{r, fig.width=5, fig.height=4, dpi=100}
plot(cvfit)
```

And, as with `ptLasso`, we can `predict`. By default, `predict` uses the $\alpha$ that minimized the cross validated MSE:
```{r}
preds = predict(cvfit, xtest, groupstest=groupstest, ytest=ytest)
preds
```

We could instead use the argument `alphatype = "varying"` to use the $\alpha$ that minimizes the CV MSE for each individual group:
```{r}
preds = predict(cvfit, xtest, groupstest=groupstest, ytest=ytest, 
                alphatype="varying")
preds
```

