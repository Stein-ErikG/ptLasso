% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ptLassoMult.R
\name{cv.ptLassoMult}
\alias{cv.ptLassoMult}
\title{Cross-validation for ptLassoMult}
\usage{
cv.ptLassoMult(
  x,
  y,
  alphalist = seq(0, 1, length = 11),
  type.measure = c("default", "mse", "mae", "deviance"),
  nfolds = 10,
  foldid = NULL,
  verbose = FALSE,
  fitoverall = NULL,
  fitind = NULL,
  s = "lambda.min",
  gamma = "gamma.min",
  ...
)
}
\arguments{
\item{x}{\code{x} matrix as in \code{ptLassoMult}.}

\item{y}{\code{y} matrix as in \code{ptLassoMult}.}

\item{alphalist}{A vector of values of the pretraining hyperparameter alpha. Defaults to \code{seq(0, 1, length.out=11)}. This function will do pretraining for each choice of alpha in alphalist and return the CV performance for each alpha.}

\item{type.measure}{Measure computed in \code{cv.glmnet}, as in \code{ptLassoMult}.}

\item{nfolds}{Number of folds for CV (default is 10). Although \code{nfolds}can be as large as the sample size (leave-one-out CV), it is not recommended for large datasets. Smallest value allowable is \code{nfolds = 3}.}

\item{foldid}{An optional vector of values between 1 and \code{nfolds} identifying what fold each observation is in. If supplied, \code{nfolds} can be missing.}

\item{verbose}{If \code{verbose=1}, print a statement showing which model is currently being fit.}

\item{fitoverall}{An optional cv.glmnet object specifying the multiresponse model. This should have been trained on the full training data, with the argument keep = TRUE.}

\item{fitind}{An optional list of cv.glmnet objects specifying the individual models. These should have been trained on the training data, with the argumnet keep = TRUE.}

\item{s}{The choice of lambda to be used by all models when estimating the CV performance for each choice of alpha. Defaults to "lambda.min". May be "lambda.1se", or a numeric value. (Use caution when supplying a numeric value: the same lambda will be used for all models.)}

\item{gamma}{For use only when \code{relax = TRUE}. The choice of gamma to be used by all models when estimating the CV performance for each choice of alpha. Defaults to "gamma.min". May also be "gamma.1se".}

\item{\dots}{Additional arguments to be passed to the `cv.glmnet` function. Notable choices include \code{"trace.it"} and \code{"parallel"}. If \code{trace.it = TRUE}, then a progress bar is displayed for each call to \code{cv.glmnet}; useful for big models that take a long time to fit. If \code{parallel = TRUE}, use parallel \code{foreach} to fit each fold.  Must register parallel before hand, such as \code{doMC} or others. Importantly, \code{"cv.ptLasso"} does not support the arguments \code{"intercept"}, \code{"offset"}, \code{"fit"} and \code{"check.args"}.}
}
\value{
An object of class \code{"cv.ptLasso"}, which is a list with the ingredients of the cross-validation fit.
\item{call}{The call that produced this object.}
\item{alphahat}{Value of \code{alpha} that optimizes CV performance on all data.}
\item{varying.alphahat}{Vector of values of \code{alpha}, the kth of which optimizes performance for response k.}
\item{alphalist}{Vector of all alphas that were compared.}
\item{errall}{CV performance for the overall model.}
\item{errpre}{CV performance for the pretrained models (one for each \code{alpha} tried).}
\item{errind}{CV performance for the individual model.}
\item{fit}{List of \code{ptLassoMult} objects, one for each \code{alpha} tried.}
\item{fitoverall}{The fitted overall model used for the first stage of pretraining.}
\item{fitoverall.lambda}{The value of \code{lambda} used for the first stage of pretraining.}
\item{fitind}{A list containing one individual model for each group.}
\item{type.measure}{The type.measure used.}
}
\description{
Cross-validation for \code{ptLassoMult}.
}
\details{
This function runs \code{ptLassoMult} once for each requested choice of alpha, and returns the cross validated performance.
}
\examples{
# Getting started. First, we simulate data: we need covariates x and multiresponse y.
set.seed(1234)
n = 1000; ntrain = 500;
p = 500
sigma = 2
     
x = matrix(rnorm(n*p), n, p)
beta1 = c(rep(1, 5), rep(0.5, 5), rep(0, p - 10))
beta2 = c(rep(1, 5), rep(0, 5), rep(0.5, 5), rep(0, p - 15))

mu = cbind(x \%*\% beta1, x \%*\% beta2)
y  = cbind(mu[, 1] + sigma * rnorm(n), 
           mu[, 2] + sigma * rnorm(n))
cat("SNR for the two tasks:", round(diag(var(mu)/var(y-mu)), 2), fill=TRUE)
cat("Correlation between two tasks:", cor(y[, 1], y[, 2]), fill=TRUE)

xtest = x[-(1:ntrain), ]
ytest = y[-(1:ntrain), ]

x = x[1:ntrain, ]
y = y[1:ntrain, ]

# Now, we can fit a ptLasso multiresponse model:
fit = cv.ptLassoMult(x, y, type.measure = "mse")
# plot(fit) # to see the cv curve.
predict(fit, xtest) # to predict on new data
predict(fit, xtest, ytest=ytest) # if ytest is included, we also measure performance
# By default, we used s = "lambda.min" to compute CV performance.
# We could instead use s = "lambda.1se":
cvfit = cv.ptLassoMult(x, y, type.measure = "mse", s = "lambda.1se")

# We could also use the glmnet option relax = TRUE:
cvfit = cv.ptLassoMult(x, y, type.measure = "mse", relax = TRUE)
# And, as we did with lambda, we may want to specify the choice of gamma to compute CV performance:
cvfit = cv.ptLassoMult(x, y, type.measure = "mse", relax = TRUE, gamma = "gamma.1se")

# Note that the first stage of pretraining uses "lambda.1se" and "gamma.1se" by default.
# This behavior can be modified by specifying overall.lambda and overall.gamma;
# see the documentation for ptLasso for more information.


}
\seealso{
\code{\link{ptLassoMult}} and \code{\link{plot.cv.ptLasso}}.
}
